{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latihan Hyperparameter Tuning Klasifikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (700, 48)\n",
      "Shape of testing data: (300, 48)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Mengunduh dataset German Credit dari OpenML\n",
    "X, y = fetch_openml(name='credit-g', version=1, return_X_y=True, as_frame=True)\n",
    "\n",
    "# Konversi target menjadi numerik \n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y) # Mengubah 'good' menjadi 1 dan 'bad' menjadi 0\n",
    "\n",
    "# Melakukan One-Hot Encoding pada fitur kategorikal \n",
    "X_encoded = pd.get_dummies(X, drop_first=True) # konversi fitur kategorikal menjadi numerik\n",
    "\n",
    "# Membagi dataset menjadi training set dan testing set (70% training, 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Shape of training data:\", X_train.shape)\n",
    "print(\"Shape of testing data:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial laccuracy on test set (without tuning): 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Inisialisasi model Random Forest tanpa hyperparameter tuning\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluasi awal model tanpa tuning\n",
    "initial_score = rf.score(X_test, y_test)\n",
    "print(f'Initial laccuracy on test set (without tuning): {initial_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Best Parameters (Grid Search): {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Accuracy after grid search: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definisikan parameter grid untuk Grid Search \n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Inisialisasi GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output hasil terbaik \n",
    "print(f'Best Parameters (Grid Search): {grid_search.best_params_}')\n",
    "best_rf_grid = grid_search.best_estimator_\n",
    "\n",
    "# Evaluasi peforma model saat test set \n",
    "grid_search_score = best_rf_grid.score(X_test, y_test)\n",
    "print(f\"Accuracy after grid search: {grid_search_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best parameters (Random Search): {'n_estimators': np.int64(200), 'min_samples_split': 5, 'max_depth': np.int64(30), 'criterion': 'gini'}\n",
      "Evaluasi After random search: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Definisinak ruang pencarian untuk random search\n",
    "param_dist = {\n",
    "    'n_estimators': np.linspace(100, 500, 5, dtype=int),\n",
    "    'max_depth': np.linspace(10, 50, 5, dtype=int),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Inisialisasi RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=20, cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Output hasil terbaik \n",
    "print(f\"Best parameters (Random Search): {random_search.best_params_}\")\n",
    "best_rf_random = random_search.best_estimator_\n",
    "\n",
    "# Evaluasi peforma model pada saat test set\n",
    "random_search_score = best_rf_random.score(X_test, y_test)\n",
    "print(f'Evaluasi After random search: {random_search_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Best parameters (Bayesian Optimization): OrderedDict({'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 369})\n",
      "Accuracy after Bayesian Optimization: 0.75\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Definisikan ruang pencarian untuk Bayesian Optimization\n",
    "param_space = {\n",
    "    'n_estimators': (100, 500),\n",
    "    'max_depth': (10, 50),\n",
    "    'min_samples_split': (2, 10),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Inisialisasi BayesSearchCV\n",
    "bayes_search = BayesSearchCV(estimator=rf, search_spaces=param_space, n_iter=32, cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Output hasil terbaik\n",
    "print(f\"Best parameters (Bayesian Optimization): {bayes_search.best_params_}\")\n",
    "best_rf_bayes = bayes_search.best_estimator_\n",
    " \n",
    "# Evaluasi performa model pada test set\n",
    "bayes_search_score = best_rf_bayes.score(X_test, y_test)\n",
    "print(f\"Accuracy after Bayesian Optimization: {bayes_search_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seperti yang sudah kita bahas penurunan akurasi setelah hyperparameter tuning adalah hal yang umum terjadi dalam pembangunan model machine learning, dan beberapa faktor yang berkontribusi terhadap maslah ini anatara lain sebagai berikut\n",
    "\n",
    "1. Overfitting: tuning hyperparameter secara berlebihan bisa menyebabkakn model selalu sesuai dengan data pelatihan (overfit). hal ini menyebabkan peforma model yang baik pada data pelatihan tetapi buruk pada data pengujian\n",
    "2. Underfitting: sebaliknya, jika model tidak cukup kompleks setelah tuning, model bisa gagal menangkap pola penting dari data (underfit).\n",
    "3. Pemilihan Ruang Pencarian yang Tidak Tepat: jika rentang atau ruang hyperparameter yang dicari terlalu kecil atau tidak mencakup area yang optimal, hasil tuning dapat merugikan performa model.\n",
    "4. Evaluasi yang Tidak Konsisten: cross-validation yang kurang efektif atau ruang pencarian hyperparameter yang terlalu besar juga dapat membuat tuning kurang efektif.\n",
    "\n",
    "untuk melakukan tuning yang lebih baik, anda dapat meerapakan beberapa saran berikut\n",
    "1. memastikan bahwa dataset yang digunakan sudah baik\n",
    "2. memperluas ruang pencarian hyperparamter\n",
    "3. memfokuskan tuning pada hyperparametr kunci yang aling berdampak pada peforma model, seperti n_estimators, max_depth, dan min_samples_split.\n",
    "4. Menggunakan cross-validation dengan lebih banyak fold untuk membuat evaluasi performa lebih stabil.\n",
    "5. Memperhatikan keseimbangan antara eksplorasi dan eksploitasi hyperparameter dengan menggunakan metode seperti Bayesian Optimization yang lebih efisien dalam memprediksi kombinasi optimal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
